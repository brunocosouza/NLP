{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finding Synonyms and Analogies.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPKc6dNhuhRn1u4CQMCD3lf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA4-jfHRBM7B"
      },
      "source": [
        "## Encontrando Sinonimos e Analogias\r\n",
        "\r\n",
        "Esse notebook tem o objetivo de codificar (encode) as palavras utilizando um modelo pretreinado. Cada palavra sera codificada em um vetor de dim = 50 (pré-estabelecido pelo modelo). Dessa forma, com as palavras em uma dimensão vetorizada podemos encontrar similaridade entre elas, ou seja, encontrar sinônimos e analogias.\r\n",
        "\r\n",
        "Para ser mais objetivo, a palavra 'chip' por exemplo, sera codificada em um vetor de dim = 50 ou seja :\r\n",
        "\r\n",
        "chip  =  [-0.7710, -1.1697,  1.5195,  0.8371,  0.7419, -0.2185, -0.7212, -0.9400,-0.0113,  0.5485,  0.4040, -0.1846, -0.4630,  0.2620, -0.6464,  0.3599,\r\n",
        "-0.8610, -0.3869, -0.0271, -1.0254,  0.3280, -0.7500, -0.6859, -0.6912, 0.3429, -0.6660, -0.2910, -0.6104,  0.3322, -0.4252,  2.4573, -0.8748, 0.4891,  1.2888,  0.5780, -0.5509, -0.2263,  0.8127,  0.7048, -0.5498, 0.3620, -0.2171, -0.2991,  0.2917,  1.2260,  0.2446,  1.2133, -0.0967, 0.0474,  0.1971]\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZaobOvaBT9x",
        "outputId": "2956f724-0516-4584-a3f5-92290749b1db"
      },
      "source": [
        "!pip install -U d2l\r\n",
        "from d2l import torch as d2l\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting d2l\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/84/35131831bc4c0121d48c7d64a49d2dd6e4891840b7c0c5169bb4eb7ecad2/d2l-0.16.0-py3-none-any.whl (76kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20kB 21.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 61kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from d2l) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: jupyter in /usr/local/lib/python3.6/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from d2l) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2l) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (4.10.1)\n",
            "Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.6.1)\n",
            "Requirement already satisfied, skipping upgrade: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.3.1)\n",
            "Requirement already satisfied, skipping upgrade: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (7.6.3)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2l) (5.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->d2l) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2l) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2l) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.8.4)\n",
            "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (1.4.3)\n",
            "Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (5.0.8)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (4.7.0)\n",
            "Requirement already satisfied, skipping upgrade: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2l) (0.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2l) (0.9.2)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (20.0.0)\n",
            "Requirement already satisfied, skipping upgrade: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2l) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l) (3.5.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2l) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2l) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->d2l) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->d2l) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (51.1.1)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2l) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2l) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l) (20.8)\n",
            "Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2l) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2l) (0.2.5)\n",
            "Installing collected packages: d2l\n",
            "Successfully installed d2l-0.16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0bC64N1BWPj"
      },
      "source": [
        "#@save\r\n",
        "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\r\n",
        "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\r\n",
        "\r\n",
        "#@save\r\n",
        "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\r\n",
        "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\r\n",
        "\r\n",
        "#@save\r\n",
        "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\r\n",
        "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\r\n",
        "\r\n",
        "#@save\r\n",
        "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\r\n",
        "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAoIFyikB0S_",
        "outputId": "0f535ac4-8925-4128-d567-d5810b93f800"
      },
      "source": [
        "d2l.DATA_HUB['glove.6b.50d']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip',\n",
              " '0b8703943ccdb6eb788e6f091b8946e82231bc4d')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MCPSDJCCfU3"
      },
      "source": [
        "class TokenEmbedding:\r\n",
        "    def __init__(self, embedding_name):\r\n",
        "      self.idx_to_token, self.idx_to_vec = self._load_embedding(embedding_name)\r\n",
        "      self.unknown_idx = 0\r\n",
        "      self.token_to_idx = {token: idx for idx, token in \r\n",
        "                         enumerate(self.idx_to_token)}\r\n",
        "    \r\n",
        "    def _load_embedding(self, embedding_name):\r\n",
        "        idx_to_token, idx_to_vec = ['<unk>'], []\r\n",
        "        data_dir = d2l.download_extract(embedding_name)\r\n",
        "        # GloVe website: https://nlp.stanford.edu/projects/glove/\r\n",
        "        # fastText website: https://fasttext.cc/\r\n",
        "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\r\n",
        "            for line in f:\r\n",
        "                elems = line.rstrip().split(' ')\r\n",
        "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\r\n",
        "                # Skip header information, such as the top row in fastText\r\n",
        "                if len(elems) > 1:\r\n",
        "                    idx_to_token.append(token)\r\n",
        "                    idx_to_vec.append(elems)\r\n",
        "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\r\n",
        "        return idx_to_token, torch.tensor(idx_to_vec)\r\n",
        "\r\n",
        "    def __getitem__(self, tokens):\r\n",
        "      indices = [self.token_to_idx.get(token, self.unknown_idx) for token in tokens]\r\n",
        "      vecs = self.idx_to_vec[torch.tensor(indices)]\r\n",
        "      return vecs\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "      return len(self.idx_to_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E1xXIWsFLhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927aef76-ee28-4062-d293-be59a89fb2a3"
      },
      "source": [
        "glove_6b50d = TokenEmbedding('glove.6b.50d')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ../data/glove.6B.50d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA3C_bnDF77J",
        "outputId": "72928150-c4cd-4bb8-dcb0-750a43969d75"
      },
      "source": [
        "glove_6b50d.token_to_idx['science'], glove_6b50d.idx_to_token[1122]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1122, 'science')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko4QQ-AqJJIS",
        "outputId": "2a217fc5-427a-48bd-ecb1-9c84e6a26c9c"
      },
      "source": [
        "glove_6b50d[['chip']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7710, -1.1697,  1.5195,  0.8371,  0.7419, -0.2185, -0.7212, -0.9400,\n",
              "         -0.0113,  0.5485,  0.4040, -0.1846, -0.4630,  0.2620, -0.6464,  0.3599,\n",
              "         -0.8610, -0.3869, -0.0271, -1.0254,  0.3280, -0.7500, -0.6859, -0.6912,\n",
              "          0.3429, -0.6660, -0.2910, -0.6104,  0.3322, -0.4252,  2.4573, -0.8748,\n",
              "          0.4891,  1.2888,  0.5780, -0.5509, -0.2263,  0.8127,  0.7048, -0.5498,\n",
              "          0.3620, -0.2171, -0.2991,  0.2917,  1.2260,  0.2446,  1.2133, -0.0967,\n",
              "          0.0474,  0.1971]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C6aoz10HZWY"
      },
      "source": [
        "## Applying Pretrained Word Vectors\r\n",
        "\r\n",
        "### Encontrando Sinonimos. \r\n",
        "\r\n",
        "Usaremos o methodo k-nearest neighbors para procurar sinônimos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RIb1QdyHWko"
      },
      "source": [
        "def knn(W, x, k):\r\n",
        "    # The added 1e-9 is for numerical stability\r\n",
        "    cos = torch.mv(W, x.reshape(-1,)) / (\r\n",
        "        torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) *\r\n",
        "        torch.sqrt((x * x).sum()))\r\n",
        "    _, topk = torch.topk(cos, k=k)\r\n",
        "    return topk, [cos[int(i)] for i in topk]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tSaFjuaIoZq"
      },
      "source": [
        "def get_similar_tokens(query_token, k, embed):\r\n",
        "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\r\n",
        "    for i, c in zip(topk[1:], cos[1:]):  # Remove input words\r\n",
        "        print(f'cosine sim={float(c):.3f}: {embed.idx_to_token[int(i)]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cTkoircIw4A"
      },
      "source": [
        "topk, cos = knn(glove_6b50d.idx_to_vec, glove_6b50d[['chip']], 3 + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUf97oykLump",
        "outputId": "f81f2ec1-cf27-4a9e-b9f1-b32e609458d6"
      },
      "source": [
        "get_similar_tokens('chip', 4, glove_6b50d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.856: chips\n",
            "cosine sim=0.749: intel\n",
            "cosine sim=0.749: electronics\n",
            "cosine sim=0.731: semiconductor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqr-sibuMZKR",
        "outputId": "77f57752-55cb-45d8-b412-48d3a64d798b"
      },
      "source": [
        "get_similar_tokens('science', 4, glove_6b50d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.855: sciences\n",
            "cosine sim=0.844: research\n",
            "cosine sim=0.839: institute\n",
            "cosine sim=0.837: studies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdUVe2OoMfhw",
        "outputId": "42423247-a94f-48b1-e29a-d8b92bc26ad7"
      },
      "source": [
        "get_similar_tokens('queen', 4, glove_6b50d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.852: princess\n",
            "cosine sim=0.805: lady\n",
            "cosine sim=0.787: elizabeth\n",
            "cosine sim=0.784: king\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc79F0VALp2x"
      },
      "source": [
        "### Cosseno calculo separado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVklV10KLNuw",
        "outputId": "510ca1ca-9094-4f06-c694-f865c37cab77"
      },
      "source": [
        "glove_6b50d[['chip']].reshape(-1,).shape, glove_6b50d.idx_to_vec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50]), torch.Size([400001, 50]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ21THH1Kzzp",
        "outputId": "3bf70709-9a7b-4ffe-a3bf-8fe56ee54956"
      },
      "source": [
        "cos = torch.mv(glove_6b50d.idx_to_vec, glove_6b50d[['chip']].reshape(-1,)) / (\r\n",
        "        torch.sqrt(torch.sum(glove_6b50d.idx_to_vec * glove_6b50d.idx_to_vec, axis=1) + 1e-9) *\r\n",
        "        torch.sqrt((glove_6b50d[['chip']] * glove_6b50d[['chip']]).sum()))\r\n",
        "cos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0000,  0.3935,  0.4617,  ..., -0.2265, -0.1674, -0.3025])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6W2fPCsN76D"
      },
      "source": [
        "### Encontrando Analogia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLKoTHp-OAct"
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\r\n",
        "  vecs = embed[[token_a, token_b, token_c]]\r\n",
        "  x = vecs[1] - vecs[0] + vecs[2]\r\n",
        "  topk, cos = knn(embed.idx_to_vec, x , 1)\r\n",
        "  return embed.idx_to_token[int(topk[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M-KaaN_ZRDWs",
        "outputId": "a4860706-0044-48cf-9f16-ab3481ca1de6"
      },
      "source": [
        "get_analogy('man', 'woman', 'son', glove_6b50d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'daughter'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OIC-EocQRJq5",
        "outputId": "f19ad249-eef7-42e6-dad8-64eb8ed1bfd5"
      },
      "source": [
        "get_analogy('bad', 'worst', 'big', glove_6b50d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'biggest'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}
